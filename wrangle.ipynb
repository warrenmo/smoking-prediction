{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from os import listdir\n",
    "\n",
    "from dask.dataframe import from_pandas\n",
    "from multiprocessing import cpu_count, Pool\n",
    "\n",
    "from config import PURE_TRAIN_PATH, PURE_VAL_PATH, ORIG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are the columns aligned? (so we can skip reading them in the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_1 = pd.read_csv(PURE_TRAIN_PATH, nrows=1)\n",
    "# val_1 = pd.read_csv(PURE_VAL_PATH, nrows=1)\n",
    "# all(train_sample.columns == val_sample.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Float64 seems like overkill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = pd.read_csv(PURE_TRAIN_PATH, skiprows=1, nrows=1, header=None)\n",
    "float32_cols = {col: np.float32 for col in train_1 if train_1[col].dtype=='float64'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are there any null values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(PURE_TRAIN_PATH,\n",
    "                    skiprows=1,\n",
    "                    engine='c',\n",
    "                    delimiter=',',\n",
    "                    low_memory=False,\n",
    "                    dtype=float32_cols,\n",
    "                   )\n",
    "\n",
    "print(train.isnull().values.any())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "val = pd.read_csv(PURE_VAL_PATH,\n",
    "                  skiprows=1,\n",
    "                  engine='c',\n",
    "                  delimiter=',',\n",
    "                  low_memory=False,\n",
    "                  dtype=float32_cols,\n",
    "                 )\n",
    "\n",
    "print(val.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's see the improvements (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.9 s ± 24.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pd.read_csv(PURE_TRAIN_PATH, skiprows=1, nrows=10, engine='c', delimiter=',', na_filter=False, low_memory=False, dtype=float32_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.1 s ± 270 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pd.read_csv(PURE_TRAIN_PATH, nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.read_csv(PURE_TRAIN_PATH,\n",
    "                  skiprows=1,\n",
    "                  nrows=10,\n",
    "                  engine='c',\n",
    "                  delimiter=',',\n",
    "                  na_filter=False,\n",
    "                  low_memory=False,\n",
    "                  dtype=float32_cols,\n",
    "                 )\n",
    "\n",
    "old = pd.read_csv(PURE_TRAIN_PATH,\n",
    "                  nrows=10,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new way to read in the train data uses 50.00% less memory\n"
     ]
    }
   ],
   "source": [
    "ratio = new.memory_usage(deep=True).sum() / old.memory_usage(deep=True).sum()\n",
    "print(f\"The new way to read in the train data uses {1-ratio:.2%} less memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...probably due to using float32 instead of float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.2 s ± 650 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pd.read_csv(PURE_TRAIN_PATH, skiprows=1, engine='c', delimiter=',', na_filter=False, low_memory=False, dtype=float32_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2min 14s ± 328 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.loadtxt(PURE_TRAIN_PATH, skiprows=1, delimiter=',', dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating (data from targets)\n",
    "Want to try out transformations on X (and not y), so let's separate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(PURE_TRAIN_PATH,\n",
    "                    skiprows=1,\n",
    "                    dtype=float32_cols,\n",
    "                    delimiter=',',\n",
    "                    header=None,\n",
    "                    engine='c',\n",
    "                    na_filter=False,\n",
    "                    low_memory=False,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train.iloc[:,:-1], train.iloc[:,-1]\n",
    "train_x.to_csv(ORIG_DIR / 'train_data.csv', header=False, index=False)\n",
    "train_y.to_csv(ORIG_DIR / 'train_targets.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.read_csv(PURE_VAL_PATH,\n",
    "                  skiprows=1,\n",
    "                  dtype=float32_cols,\n",
    "                  delimiter=',',\n",
    "                  header=None,\n",
    "                  engine='c',\n",
    "                  na_filter=False,\n",
    "                  low_memory=False,\n",
    "                 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x, val_y = val.iloc[:,:-1], val.iloc[:,-1]\n",
    "val_x.to_csv(ORIG_DIR / 'val_data.csv', header=False, index=False)\n",
    "val_y.to_csv(ORIG_DIR / 'val_targets.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_TRAIN_PATH = ORIG_DIR / 'train_data.csv'\n",
    "X_VAL_PATH = ORIG_DIR / 'val_data.csv'\n",
    "SPLIT_DIR = ORIG_DIR / 'mp_split'\n",
    "NUM_SPLITS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enum_splits(title, X, axis=0, *, num_splits):\n",
    "    return [(i, title, split) for i, split in \n",
    "            enumerate(np.array_split(X, num_splits, axis=axis))]\n",
    "\n",
    "def save_split(i_title_split):\n",
    "    i, title, split = i_title_split\n",
    "    np.savetxt(SPLIT_DIR/title/f'{i:02d}.csv', split, delimiter=',', fmt='%f')\n",
    "    \n",
    "def read_csv_custom(path, *, asarray, **kwargs):\n",
    "    X = pd.read_csv(path,\n",
    "                    header=None,\n",
    "                    engine='c',\n",
    "                    delimiter=',',\n",
    "                    na_filter=False,\n",
    "                    low_memory=False,\n",
    "                    dtype=np.float32,\n",
    "                    **kwargs\n",
    "                   )\n",
    "    return np.asarray(X) if asarray else X\n",
    "\n",
    "def _read_csv_custom_df(path):\n",
    "    return read_csv_custom(path, asarray=False)\n",
    "\n",
    "def read_csv_mp(split_subdir, *, axis, asarray=True, processes=None):\n",
    "    path_list = sorted(split_subdir/csv for csv in listdir(split_subdir))\n",
    "    with Pool(processes=processes) as pool:\n",
    "        df_list = pool.map(_read_csv_custom_df, path_list)\n",
    "    X = pd.concat(df_list, axis=axis, ignore_index=True)\n",
    "    return np.asarray(X) if asarray else X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = read_csv_custom(X_TRAIN_PATH, asarray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split on rows (axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mp_splits = enum_splits('train', X_train, axis=0)\n",
    "\n",
    "with Pool() as pool:\n",
    "    pool.map(save_split, train_mp_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464, 482739)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mp = read_csv_mp(SPLIT_DIR/'train', axis=0)\n",
    "X_train_mp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(X_train, np.asarray(X_train_mp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.1 s ± 452 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit read_csv_mp(SPLIT_DIR/'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split on cols (axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mp_splits = enum_splits('train', X_train, axis=1, num_splits=NUM_SPLITS)\n",
    "\n",
    "with Pool() as pool:\n",
    "    pool.map(save_split, train_mp_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464, 482739)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mp = read_csv_mp(SPLIT_DIR/'train', axis=1)\n",
    "X_train_mp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(X_train, np.asarray(X_train_mp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### num_splits = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.6 s ± 227 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit read_csv_mp(SPLIT_DIR/'train', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### num_splits = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.2 s ± 195 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit read_csv_mp(SPLIT_DIR/'train', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### num_splits = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.1 s ± 83 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit read_csv_mp(SPLIT_DIR/'train', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### num_splits = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.5 s ± 229 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit read_csv_mp(SPLIT_DIR/'train', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### num_splits = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.3 s ± 169 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit read_csv_mp(SPLIT_DIR/'train', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's also split the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = read_csv_custom(X_VAL_PATH)\n",
    "X_val = np.asarray(X_val)\n",
    "val_mp_splits = enum_splits('val', X_val, axis=1, num_splits=NUM_SPLITS)\n",
    "\n",
    "with Pool() as pool:\n",
    "    pool.map(save_split, val_mp_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3)",
   "language": "python",
   "name": "conda_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
